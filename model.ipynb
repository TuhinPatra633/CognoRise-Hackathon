{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "test_data = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roll no</th>\n",
       "      <th>test preparation</th>\n",
       "      <th>gender</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>Section</th>\n",
       "      <th>practical score</th>\n",
       "      <th>viva score</th>\n",
       "      <th>exam score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXA000001</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>Section A</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXA000002</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>Section C</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXA000003</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>Section E</td>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXA000004</td>\n",
       "      <td>none</td>\n",
       "      <td>female</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>Section C</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXA000005</td>\n",
       "      <td>none</td>\n",
       "      <td>female</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>Section C</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31994</th>\n",
       "      <td>EXA031995</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>some high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>Section E</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>EXA031996</td>\n",
       "      <td>none</td>\n",
       "      <td>female</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>Section B</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>EXA031997</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>Section B</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>EXA031998</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>Section D</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>EXA031999</td>\n",
       "      <td>none</td>\n",
       "      <td>male</td>\n",
       "      <td>some high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>Section C</td>\n",
       "      <td>51</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31999 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Roll no test preparation   gender parental level of education  \\\n",
       "0      EXA000001              none    male                some college   \n",
       "1      EXA000002              none    male             master's degree   \n",
       "2      EXA000003              none    male             master's degree   \n",
       "3      EXA000004              none  female                some college   \n",
       "4      EXA000005              none  female                 high school   \n",
       "...          ...               ...     ...                         ...   \n",
       "31994  EXA031995              none    male            some high school   \n",
       "31995  EXA031996              none  female                 high school   \n",
       "31996  EXA031997              none    male           bachelor's degree   \n",
       "31997  EXA031998              none    male          associate's degree   \n",
       "31998  EXA031999              none    male            some high school   \n",
       "\n",
       "              lunch    Section  practical score  viva score  exam score  \n",
       "0          standard  Section A               70          73          70  \n",
       "1      free/reduced  Section C               55          54          52  \n",
       "2      free/reduced  Section E               56          46          43  \n",
       "3      free/reduced  Section C               35          47          41  \n",
       "4          standard  Section C               87          92          81  \n",
       "...             ...        ...              ...         ...         ...  \n",
       "31994  free/reduced  Section E               63          53          80  \n",
       "31995      standard  Section B              100          80          68  \n",
       "31996  free/reduced  Section B               62          61          74  \n",
       "31997      standard  Section D               75          32          82  \n",
       "31998      standard  Section C               51          92          82  \n",
       "\n",
       "[31999 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Roll no  test preparation   gender  parental level of education  lunch  \\\n",
      "0  EXA000001                  1       1                            4      1   \n",
      "1  EXA000002                  1       1                            3      0   \n",
      "2  EXA000003                  1       1                            3      0   \n",
      "3  EXA000004                  1       0                            4      0   \n",
      "4  EXA000005                  1       0                            2      1   \n",
      "\n",
      "   Section  practical score  viva score  exam score  \n",
      "0        0               70          73          70  \n",
      "1        2               55          54          52  \n",
      "2        4               56          46          43  \n",
      "3        2               35          47          41  \n",
      "4        2               87          92          81  \n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['test preparation ', 'gender', 'parental level of education', 'lunch', 'Section']\n",
    "\n",
    "# Applying LabelEncoder to each categorical column\n",
    "for column in categorical_columns:\n",
    "    encoded_data[column] = le.fit_transform(encoded_data[column])\n",
    "for column in categorical_columns:\n",
    "    test_data[column] = le.fit_transform(test_data[column])\n",
    "\n",
    "# Display the first few rows of the encoded dataframe\n",
    "print(encoded_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.drop(columns=[\"Roll no\"],inplace=True)\n",
    "test_data.drop(columns=[\"Roll no\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test preparation</th>\n",
       "      <th>gender</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>Section</th>\n",
       "      <th>practical score</th>\n",
       "      <th>viva score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test preparation   gender  parental level of education  lunch  Section  \\\n",
       "0                   1       1                            0      1        2   \n",
       "1                   0       1                            5      1        4   \n",
       "2                   1       1                            5      1        2   \n",
       "3                   0       1                            5      1        3   \n",
       "4                   1       0                            1      1        4   \n",
       "..                ...     ...                          ...    ...      ...   \n",
       "95                  1       1                            1      1        1   \n",
       "96                  0       1                            0      0        1   \n",
       "97                  1       1                            4      1        2   \n",
       "98                  0       1                            0      1        0   \n",
       "99                  1       1                            2      1        1   \n",
       "\n",
       "    practical score  viva score  \n",
       "0                74          89  \n",
       "1                66          75  \n",
       "2                52          55  \n",
       "3                69          85  \n",
       "4                46          62  \n",
       "..              ...         ...  \n",
       "95               82          84  \n",
       "96               70          58  \n",
       "97               76          67  \n",
       "98               62          71  \n",
       "99               58          67  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lable = encoded_data.pop(\"exam score\")\n",
    "x_train,x_val,y_train,y_val = train_test_split(encoded_data,lable,test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test preparation</th>\n",
       "      <th>gender</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>Section</th>\n",
       "      <th>practical score</th>\n",
       "      <th>viva score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23553</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22030</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22726</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27927</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25599 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test preparation   gender  parental level of education  lunch  Section  \\\n",
       "23553                  1       0                            0      1        4   \n",
       "22030                  1       0                            4      0        3   \n",
       "265                    1       1                            0      1        0   \n",
       "22726                  1       0                            4      0        1   \n",
       "27927                  1       0                            3      1        2   \n",
       "...                  ...     ...                          ...    ...      ...   \n",
       "29802                  0       1                            0      0        1   \n",
       "5390                   1       0                            0      0        4   \n",
       "860                    1       1                            0      1        3   \n",
       "15795                  1       0                            0      1        4   \n",
       "23654                  1       0                            4      0        2   \n",
       "\n",
       "       practical score  viva score  \n",
       "23553               72          92  \n",
       "22030               76          73  \n",
       "265                 37          40  \n",
       "22726               69          61  \n",
       "27927               80          66  \n",
       "...                ...         ...  \n",
       "29802               86          79  \n",
       "5390                64          72  \n",
       "860                 61          56  \n",
       "15795              100          82  \n",
       "23654               82          57  \n",
       "\n",
       "[25599 rows x 7 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regressor = DecisionTreeRegressor(max_depth=5)\n",
    "tree_regressor.fit(x_train,y_train)\n",
    "y_train_pred = tree_regressor.predict(x_train)\n",
    "y_val_pred = tree_regressor.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 224.0912181255792\n",
      "Mean Squared Error (MSE) on Validation data: 221.82449336924458\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on Validation data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth1 = [5,10,15,25,50,75,100]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in max_depth1:\n",
    "    tree_c= DecisionTreeRegressor(max_depth = i)\n",
    "    tree_c.fit(x_train,y_train)\n",
    "    y_train_pred = tree_c.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = tree_c.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "plt.plot(max_depth1,train_result, marker='o', linestyle='-')\n",
    "plt.plot(max_depth1,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_fe1 = [5,8,12,15,18,23,30]\n",
    "train_result=[]\n",
    "val_result=[]\n",
    "for i in max_fe1:\n",
    "    tree_= DecisionTreeRegressor(max_features = i)\n",
    "    tree_c.fit(x_train,y_train)\n",
    "    y_train_pred = tree_c.predict(x_train)\n",
    "    train_result.append(mean_squared_error(y_train, y_train_pred))\n",
    "    y_val_pred = tree_c.predict(x_val)\n",
    "    val_result.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(max_fe1,train_result, marker='o', linestyle='-')\n",
    "plt.plot(max_fe1,val_result, marker='o', linestyle='-')\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Max Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth:5,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:443.03044487847217\n",
      "For max_depth:5,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.76005425347216\n",
      "For max_depth:5,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.3654535590278\n",
      "For max_depth:5,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.5208485243056\n",
      "For max_depth:5,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.29909071180555\n",
      "For max_depth:5,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.2078971354167\n",
      "For max_depth:5,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.37550130208336\n",
      "For max_depth:5,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.27841362847226\n",
      "For max_depth:5,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9391471354167\n",
      "For max_depth:5,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.0463650173611\n",
      "For max_depth:5,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.8946072048611\n",
      "For max_depth:5,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.1491644965278\n",
      "For max_depth:5,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.18087022569443\n",
      "For max_depth:5,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.0775065104167\n",
      "For max_depth:5,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.36971571180555\n",
      "For max_depth:5,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.18747178819444\n",
      "For max_depth:5,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.64939453125\n",
      "For max_depth:5,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7684136284722\n",
      "For max_depth:5,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.87304036458335\n",
      "For max_depth:5,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.3418728298611\n",
      "For max_depth:5,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.12434678819443\n",
      "For max_depth:5,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.7065082465278\n",
      "For max_depth:5,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1708615451389\n",
      "For max_depth:5,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.8999197048611\n",
      "For max_depth:5,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.1585177951389\n",
      "For max_depth:5,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.03701171875\n",
      "For max_depth:5,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.27462890625\n",
      "For max_depth:5,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.9723459201389\n",
      "For max_depth:5,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.0738302951389\n",
      "For max_depth:5,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.9596115451389\n",
      "For max_depth:5,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.7344162326389\n",
      "For max_depth:5,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.77607855902784\n",
      "For max_depth:5,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.64755859375\n",
      "For max_depth:5,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:444.26429036458336\n",
      "For max_depth:5,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.23740668402775\n",
      "For max_depth:5,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.41811848958326\n",
      "For max_depth:5,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.57401692708333\n",
      "For max_depth:5,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.39123914930565\n",
      "For max_depth:5,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9239474826389\n",
      "For max_depth:5,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.5514388020833\n",
      "For max_depth:5,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.4624631076389\n",
      "For max_depth:5,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.69990668402784\n",
      "For max_depth:5,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9447287326389\n",
      "For max_depth:5,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.6581879340278\n",
      "For max_depth:5,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.4083051215278\n",
      "For max_depth:5,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.6117426215278\n",
      "For max_depth:5,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.2457443576389\n",
      "For max_depth:5,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.65111328125\n",
      "For max_depth:5,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.0874674479167\n",
      "For max_depth:5,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.8095464409722\n",
      "For max_depth:5,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.00512803819447\n",
      "For max_depth:5,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.0274978298611\n",
      "For max_depth:5,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.8543815104167\n",
      "For max_depth:5,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.11318359375\n",
      "For max_depth:5,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.0119205729167\n",
      "For max_depth:5,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.73367838541674\n",
      "For max_depth:5,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:443.3844118923612\n",
      "For max_depth:5,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:432.45622178819445\n",
      "For max_depth:5,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.43633029513893\n",
      "For max_depth:5,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.92451171875\n",
      "For max_depth:5,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.7392947048611\n",
      "For max_depth:5,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.99912109375\n",
      "For max_depth:5,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.4428754340278\n",
      "For max_depth:5,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.17821397569446\n",
      "For max_depth:10,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.39311848958334\n",
      "For max_depth:10,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7480924479167\n",
      "For max_depth:10,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.8833615451389\n",
      "For max_depth:10,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.2281315104167\n",
      "For max_depth:10,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.0225889756945\n",
      "For max_depth:10,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.5527322048611\n",
      "For max_depth:10,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.55134765625\n",
      "For max_depth:10,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.3983441840278\n",
      "For max_depth:10,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.58051866319437\n",
      "For max_depth:10,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.7531271701389\n",
      "For max_depth:10,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.24686414930557\n",
      "For max_depth:10,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.3707052951389\n",
      "For max_depth:10,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.8283572048611\n",
      "For max_depth:10,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.4536089409722\n",
      "For max_depth:10,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9680620659723\n",
      "For max_depth:10,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.47009765625\n",
      "For max_depth:10,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.09757161458333\n",
      "For max_depth:10,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.5347894965278\n",
      "For max_depth:10,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.2961697048611\n",
      "For max_depth:10,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9649978298611\n",
      "For max_depth:10,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.40019748263893\n",
      "For max_depth:10,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.99315755208335\n",
      "For max_depth:10,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.1367990451389\n",
      "For max_depth:10,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.5385828993055\n",
      "For max_depth:10,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.46083550347225\n",
      "For max_depth:10,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.5329535590278\n",
      "For max_depth:10,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.0861610243056\n",
      "For max_depth:10,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.94811848958335\n",
      "For max_depth:10,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9335047743056\n",
      "For max_depth:10,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.4751584201389\n",
      "For max_depth:10,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.6601323784722\n",
      "For max_depth:10,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.96866102430556\n",
      "For max_depth:10,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.4512651909722\n",
      "For max_depth:10,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.5883658854167\n",
      "For max_depth:10,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.97684678819445\n",
      "For max_depth:10,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.9415082465278\n",
      "For max_depth:10,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9590169270834\n",
      "For max_depth:10,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.3117122395833\n",
      "For max_depth:10,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.72923828125\n",
      "For max_depth:10,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.8022504340278\n",
      "For max_depth:10,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.4976931423611\n",
      "For max_depth:10,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.63197265625\n",
      "For max_depth:10,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.0356401909722\n",
      "For max_depth:10,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.25225477430564\n",
      "For max_depth:10,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.7334483506944\n",
      "For max_depth:10,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.1799631076389\n",
      "For max_depth:10,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9843250868056\n",
      "For max_depth:10,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.3666948784722\n",
      "For max_depth:10,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.6102669270833\n",
      "For max_depth:10,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1791644965278\n",
      "For max_depth:10,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.30615234375\n",
      "For max_depth:10,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.14192491319443\n",
      "For max_depth:10,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.2886610243056\n",
      "For max_depth:10,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.65573133680556\n",
      "For max_depth:10,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:432.53396918402774\n",
      "For max_depth:10,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.06597005208334\n",
      "For max_depth:10,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1927322048611\n",
      "For max_depth:10,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2873415798611\n",
      "For max_depth:10,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.14131727430555\n",
      "For max_depth:10,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.39915581597216\n",
      "For max_depth:10,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.8211566840278\n",
      "For max_depth:10,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.8789040798611\n",
      "For max_depth:10,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.11291883680565\n",
      "For max_depth:10,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.6062955729166\n",
      "For max_depth:15,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.1266818576389\n",
      "For max_depth:15,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.33814453125\n",
      "For max_depth:15,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.8126236979167\n",
      "For max_depth:15,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.6385611979167\n",
      "For max_depth:15,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.5467339409722\n",
      "For max_depth:15,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.5092165798611\n",
      "For max_depth:15,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.34057942708336\n",
      "For max_depth:15,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.5528884548611\n",
      "For max_depth:15,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.7738650173611\n",
      "For max_depth:15,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.2590082465278\n",
      "For max_depth:15,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.2689431423611\n",
      "For max_depth:15,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.3674587673611\n",
      "For max_depth:15,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.0027712673611\n",
      "For max_depth:15,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.6828580729167\n",
      "For max_depth:15,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.3889822048611\n",
      "For max_depth:15,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.27037977430564\n",
      "For max_depth:15,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.39861328125\n",
      "For max_depth:15,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.52653862847217\n",
      "For max_depth:15,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.8736393229167\n",
      "For max_depth:15,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.4279318576389\n",
      "For max_depth:15,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.64619574652784\n",
      "For max_depth:15,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.7884787326389\n",
      "For max_depth:15,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:432.9441384548611\n",
      "For max_depth:15,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.0457660590278\n",
      "For max_depth:15,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.3996853298611\n",
      "For max_depth:15,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9135525173611\n",
      "For max_depth:15,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9677756076389\n",
      "For max_depth:15,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.0460785590278\n",
      "For max_depth:15,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.7754058159722\n",
      "For max_depth:15,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.4705230034722\n",
      "For max_depth:15,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9521549479167\n",
      "For max_depth:15,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.14534071180555\n",
      "For max_depth:15,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.1479709201389\n",
      "For max_depth:15,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.22450303819454\n",
      "For max_depth:15,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.7726106770834\n",
      "For max_depth:15,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.01763671875\n",
      "For max_depth:15,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:432.7476236979167\n",
      "For max_depth:15,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.90021918402783\n",
      "For max_depth:15,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.39115234375\n",
      "For max_depth:15,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.26249348958333\n",
      "For max_depth:15,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.22078776041667\n",
      "For max_depth:15,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.97037543402774\n",
      "For max_depth:15,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2836002604166\n",
      "For max_depth:15,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.42321397569447\n",
      "For max_depth:15,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.1632009548611\n",
      "For max_depth:15,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.09071831597225\n",
      "For max_depth:15,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.7892903645833\n",
      "For max_depth:15,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.72442491319447\n",
      "For max_depth:15,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.34501519097216\n",
      "For max_depth:15,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.5452669270833\n",
      "For max_depth:15,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.42449001736117\n",
      "For max_depth:15,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.9625325520833\n",
      "For max_depth:15,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.5880230034722\n",
      "For max_depth:15,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.76135199652776\n",
      "For max_depth:15,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.5830230034722\n",
      "For max_depth:15,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.78507161458333\n",
      "For max_depth:15,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.72345703125\n",
      "For max_depth:15,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.2470594618055\n",
      "For max_depth:15,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.17123480902774\n",
      "For max_depth:15,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.8369379340278\n",
      "For max_depth:15,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.20224609375\n",
      "For max_depth:15,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.11517578125\n",
      "For max_depth:15,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.1530447048611\n",
      "For max_depth:15,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.8038346354167\n",
      "For max_depth:25,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.61518880208337\n",
      "For max_depth:25,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.64055338541664\n",
      "For max_depth:25,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.5580924479167\n",
      "For max_depth:25,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.03106987847224\n",
      "For max_depth:25,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.88555338541664\n",
      "For max_depth:25,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.29470269097226\n",
      "For max_depth:25,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.45059244791673\n",
      "For max_depth:25,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.25210286458326\n",
      "For max_depth:25,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.7953927951389\n",
      "For max_depth:25,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7071332465278\n",
      "For max_depth:25,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.4952322048611\n",
      "For max_depth:25,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.4090646701389\n",
      "For max_depth:25,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.4762174479167\n",
      "For max_depth:25,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.3738736979166\n",
      "For max_depth:25,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.5195941840278\n",
      "For max_depth:25,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.6736306423611\n",
      "For max_depth:25,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9022417534722\n",
      "For max_depth:25,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.66116970486115\n",
      "For max_depth:25,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.13205946180557\n",
      "For max_depth:25,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.12189453125\n",
      "For max_depth:25,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7397938368056\n",
      "For max_depth:25,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.6881271701389\n",
      "For max_depth:25,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.66044921875\n",
      "For max_depth:25,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.94637369791667\n",
      "For max_depth:25,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.6637521701389\n",
      "For max_depth:25,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.92373046875\n",
      "For max_depth:25,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.16868706597216\n",
      "For max_depth:25,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.62046223958333\n",
      "For max_depth:25,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.8248502604167\n",
      "For max_depth:25,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1836870659722\n",
      "For max_depth:25,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.2424370659722\n",
      "For max_depth:25,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.7764040798611\n",
      "For max_depth:25,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.0504535590278\n",
      "For max_depth:25,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.1947417534722\n",
      "For max_depth:25,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.2528884548611\n",
      "For max_depth:25,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.82647352430564\n",
      "For max_depth:25,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.1765473090278\n",
      "For max_depth:25,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.4260828993055\n",
      "For max_depth:25,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.2671202256944\n",
      "For max_depth:25,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.1857052951389\n",
      "For max_depth:25,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.9100282118055\n",
      "For max_depth:25,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.5696549479167\n",
      "For max_depth:25,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1533615451389\n",
      "For max_depth:25,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.3234830729167\n",
      "For max_depth:25,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.4889605034722\n",
      "For max_depth:25,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.92322699652783\n",
      "For max_depth:25,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.3150368923611\n",
      "For max_depth:25,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1138693576389\n",
      "For max_depth:25,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.3196332465278\n",
      "For max_depth:25,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.90395182291667\n",
      "For max_depth:25,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.0991124131944\n",
      "For max_depth:25,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.5063997395833\n",
      "For max_depth:25,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7634353298612\n",
      "For max_depth:25,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.2869509548611\n",
      "For max_depth:25,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.03947265625\n",
      "For max_depth:25,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.5970334201389\n",
      "For max_depth:25,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.6463389756944\n",
      "For max_depth:25,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.36896918402783\n",
      "For max_depth:25,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2706358506945\n",
      "For max_depth:25,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7759440104167\n",
      "For max_depth:25,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.82712890625\n",
      "For max_depth:25,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.84716796875\n",
      "For max_depth:25,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.27013671875\n",
      "For max_depth:25,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.93971137152784\n",
      "For max_depth:50,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.3609787326389\n",
      "For max_depth:50,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.21888671875\n",
      "For max_depth:50,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.6559396701389\n",
      "For max_depth:50,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.22310546875\n",
      "For max_depth:50,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:444.3438302951389\n",
      "For max_depth:50,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.16952473958327\n",
      "For max_depth:50,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.57342664930553\n",
      "For max_depth:50,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.5553450520833\n",
      "For max_depth:50,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.7758615451389\n",
      "For max_depth:50,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.2670941840278\n",
      "For max_depth:50,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.63343098958336\n",
      "For max_depth:50,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.7420985243056\n",
      "For max_depth:50,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.58884331597227\n",
      "For max_depth:50,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.29490234375\n",
      "For max_depth:50,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.06657335069445\n",
      "For max_depth:50,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.2510134548611\n",
      "For max_depth:50,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.95766710069444\n",
      "For max_depth:50,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.41586588541674\n",
      "For max_depth:50,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.4182183159722\n",
      "For max_depth:50,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.36405164930557\n",
      "For max_depth:50,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.1595377604167\n",
      "For max_depth:50,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.37981119791664\n",
      "For max_depth:50,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.5250238715278\n",
      "For max_depth:50,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.2700629340278\n",
      "For max_depth:50,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7667209201389\n",
      "For max_depth:50,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.2704665798611\n",
      "For max_depth:50,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.6041080729167\n",
      "For max_depth:50,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2522938368056\n",
      "For max_depth:50,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.4477235243056\n",
      "For max_depth:50,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.88359592013893\n",
      "For max_depth:50,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.38548828125\n",
      "For max_depth:50,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.6255316840278\n",
      "For max_depth:50,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.88363498263885\n",
      "For max_depth:50,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.23780598958336\n",
      "For max_depth:50,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2487521701389\n",
      "For max_depth:50,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9042469618056\n",
      "For max_depth:50,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.6481098090278\n",
      "For max_depth:50,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.2250151909722\n",
      "For max_depth:50,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.68191189236114\n",
      "For max_depth:50,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.60544053819444\n",
      "For max_depth:50,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.2516558159722\n",
      "For max_depth:50,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.39297526041673\n",
      "For max_depth:50,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.4174761284723\n",
      "For max_depth:50,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.3971462673611\n",
      "For max_depth:50,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.85397786458327\n",
      "For max_depth:50,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.62550130208336\n",
      "For max_depth:50,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.25241536458327\n",
      "For max_depth:50,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7104578993056\n",
      "For max_depth:50,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.70533203125007\n",
      "For max_depth:50,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.08142578125\n",
      "For max_depth:50,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.22630859375\n",
      "For max_depth:50,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.4677408854166\n",
      "For max_depth:50,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.2029448784722\n",
      "For max_depth:50,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9352452256945\n",
      "For max_depth:50,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.06786241319446\n",
      "For max_depth:50,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.24395616319447\n",
      "For max_depth:50,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7518337673611\n",
      "For max_depth:50,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.8285525173611\n",
      "For max_depth:50,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.02851345486107\n",
      "For max_depth:50,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.92141710069444\n",
      "For max_depth:50,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.33393446180554\n",
      "For max_depth:50,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.07175564236115\n",
      "For max_depth:50,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1700499131945\n",
      "For max_depth:50,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.0309743923611\n",
      "For max_depth:75,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.99308376736116\n",
      "For max_depth:75,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.9929275173612\n",
      "For max_depth:75,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.4289127604167\n",
      "For max_depth:75,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.4190776909722\n",
      "For max_depth:75,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.57173828125\n",
      "For max_depth:75,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.63310546875\n",
      "For max_depth:75,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:443.21553602430555\n",
      "For max_depth:75,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7792730034722\n",
      "For max_depth:75,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.4881228298611\n",
      "For max_depth:75,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.2642947048612\n",
      "For max_depth:75,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7906575520833\n",
      "For max_depth:75,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.6328276909722\n",
      "For max_depth:75,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.50268446180553\n",
      "For max_depth:75,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.20998914930556\n",
      "For max_depth:75,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.92447265625\n",
      "For max_depth:75,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.4253754340277\n",
      "For max_depth:75,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.3880230034722\n",
      "For max_depth:75,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.7025629340278\n",
      "For max_depth:75,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.6614301215278\n",
      "For max_depth:75,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.6141037326389\n",
      "For max_depth:75,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.8770334201389\n",
      "For max_depth:75,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.87655598958327\n",
      "For max_depth:75,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.4066427951389\n",
      "For max_depth:75,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.96806206597216\n",
      "For max_depth:75,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.51256727430564\n",
      "For max_depth:75,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.82642578125\n",
      "For max_depth:75,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.93616536458336\n",
      "For max_depth:75,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.86813151041673\n",
      "For max_depth:75,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.8866818576389\n",
      "For max_depth:75,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.6898415798611\n",
      "For max_depth:75,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.3709874131944\n",
      "For max_depth:75,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.2404014756944\n",
      "For max_depth:75,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.33419487847226\n",
      "For max_depth:75,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.6084396701389\n",
      "For max_depth:75,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.3296462673611\n",
      "For max_depth:75,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.1038302951389\n",
      "For max_depth:75,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7204058159722\n",
      "For max_depth:75,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.78233723958334\n",
      "For max_depth:75,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.79793619791667\n",
      "For max_depth:75,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.3328797743055\n",
      "For max_depth:75,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.2348676215278\n",
      "For max_depth:75,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.66642578125\n",
      "For max_depth:75,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2407400173611\n",
      "For max_depth:75,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.03061848958333\n",
      "For max_depth:75,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.07896484375\n",
      "For max_depth:75,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9815863715278\n",
      "For max_depth:75,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.9291427951389\n",
      "For max_depth:75,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.77368272569447\n",
      "For max_depth:75,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.0329275173611\n",
      "For max_depth:75,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.98126953125\n",
      "For max_depth:75,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.0126714409722\n",
      "For max_depth:75,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.4814431423611\n",
      "For max_depth:75,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.82005859375\n",
      "For max_depth:75,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.2165950520833\n",
      "For max_depth:75,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.4872026909722\n",
      "For max_depth:75,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1325325520834\n",
      "For max_depth:75,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.15598741319445\n",
      "For max_depth:75,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.87321397569445\n",
      "For max_depth:75,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.77546223958336\n",
      "For max_depth:75,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.69680772569444\n",
      "For max_depth:75,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.35942491319446\n",
      "For max_depth:75,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.13360894097224\n",
      "For max_depth:75,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.4508572048611\n",
      "For max_depth:75,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.5978580729167\n",
      "For max_depth:100,max_features:None,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.3599327256945\n",
      "For max_depth:100,max_features:None,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.2797157118055\n",
      "For max_depth:100,max_features:None,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.4801931423611\n",
      "For max_depth:100,max_features:None,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.92735460069446\n",
      "For max_depth:100,max_features:None,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.30279296875\n",
      "For max_depth:100,max_features:None,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7904752604167\n",
      "For max_depth:100,max_features:None,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.90356119791664\n",
      "For max_depth:100,max_features:None,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.82939019097216\n",
      "For max_depth:100,max_features:5,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.70401692708333\n",
      "For max_depth:100,max_features:5,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.60419921875\n",
      "For max_depth:100,max_features:5,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.76068359375\n",
      "For max_depth:100,max_features:5,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.9687131076389\n",
      "For max_depth:100,max_features:5,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.02424696180555\n",
      "For max_depth:100,max_features:5,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.48844401041663\n",
      "For max_depth:100,max_features:5,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.25420355902776\n",
      "For max_depth:100,max_features:5,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.39026258680565\n",
      "For max_depth:100,max_features:8,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.18663411458334\n",
      "For max_depth:100,max_features:8,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.08618272569447\n",
      "For max_depth:100,max_features:8,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.54485460069446\n",
      "For max_depth:100,max_features:8,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.2532660590278\n",
      "For max_depth:100,max_features:8,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.7291427951389\n",
      "For max_depth:100,max_features:8,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7581228298612\n",
      "For max_depth:100,max_features:8,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.9061697048611\n",
      "For max_depth:100,max_features:8,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.41160807291664\n",
      "For max_depth:100,max_features:12,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.66912977430565\n",
      "For max_depth:100,max_features:12,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.59544053819445\n",
      "For max_depth:100,max_features:12,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.49986328125\n",
      "For max_depth:100,max_features:12,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.8362044270834\n",
      "For max_depth:100,max_features:12,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.02130859375\n",
      "For max_depth:100,max_features:12,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.66271050347217\n",
      "For max_depth:100,max_features:12,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.7528927951389\n",
      "For max_depth:100,max_features:12,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.7243120659722\n",
      "For max_depth:100,max_features:15,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.30903428819437\n",
      "For max_depth:100,max_features:15,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.9268641493056\n",
      "For max_depth:100,max_features:15,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.54893880208334\n",
      "For max_depth:100,max_features:15,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:435.4344813368056\n",
      "For max_depth:100,max_features:15,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.3881488715278\n",
      "For max_depth:100,max_features:15,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.66896484375\n",
      "For max_depth:100,max_features:15,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.59817057291673\n",
      "For max_depth:100,max_features:15,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:429.44262803819447\n",
      "For max_depth:100,max_features:18,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.6377582465277\n",
      "For max_depth:100,max_features:18,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:433.63250651041665\n",
      "For max_depth:100,max_features:18,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:434.2945724826389\n",
      "For max_depth:100,max_features:18,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.90627821180556\n",
      "For max_depth:100,max_features:18,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.4464388020834\n",
      "For max_depth:100,max_features:18,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.9518424479167\n",
      "For max_depth:100,max_features:18,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.3759743923611\n",
      "For max_depth:100,max_features:18,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.77305772569446\n",
      "For max_depth:100,max_features:23,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.5632443576389\n",
      "For max_depth:100,max_features:23,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.2307400173611\n",
      "For max_depth:100,max_features:23,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.38008897569455\n",
      "For max_depth:100,max_features:23,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.87887803819444\n",
      "For max_depth:100,max_features:23,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:437.4107660590278\n",
      "For max_depth:100,max_features:23,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.86596571180564\n",
      "For max_depth:100,max_features:23,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.1328363715278\n",
      "For max_depth:100,max_features:23,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:442.6401497395833\n",
      "For max_depth:100,max_features:30,min_samples_split:None\n",
      "            train accuracy:7.524538718960377 validation accuracy:438.09914713541673\n",
      "For max_depth:100,max_features:30,min_samples_split:1.0\n",
      "            train accuracy:7.524538718960377 validation accuracy:436.7442209201389\n",
      "For max_depth:100,max_features:30,min_samples_split:2\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.69065755208334\n",
      "For max_depth:100,max_features:30,min_samples_split:4\n",
      "            train accuracy:7.524538718960377 validation accuracy:440.75266710069445\n",
      "For max_depth:100,max_features:30,min_samples_split:8\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.51611328125\n",
      "For max_depth:100,max_features:30,min_samples_split:10\n",
      "            train accuracy:7.524538718960377 validation accuracy:441.2650021701389\n",
      "For max_depth:100,max_features:30,min_samples_split:12\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.6721940104167\n",
      "For max_depth:100,max_features:30,min_samples_split:14\n",
      "            train accuracy:7.524538718960377 validation accuracy:439.26315755208327\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "depth = [5,10,15,25,50,75,100]\n",
    "features= [None,5,8,12,15,18,23,30]\n",
    "min_samples_s = [None,1.0,2,4,8,10,12,14]\n",
    "for j in depth:\n",
    "    for k in features:\n",
    "        for l in min_samples_s:\n",
    "            tree_= DecisionTreeRegressor(max_depth = j, max_features = k, min_samples_split = l)\n",
    "            tree_c.fit(x_train,y_train)\n",
    "            y_train_pred = tree_c.predict(x_train)\n",
    "            train_accuracy = mean_squared_error(y_train, y_train_pred)\n",
    "            y_val_pred = tree_c.predict(x_val)\n",
    "            val_accuracy = mean_squared_error(y_val, y_val_pred)\n",
    "            list1.append((j,k,l,train_accuracy,val_accuracy))\n",
    "            print(f'''For max_depth:{j},max_features:{k},min_samples_split:{l}\n",
    "            train accuracy:{train_accuracy} validation accuracy:{val_accuracy}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 25599, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 69.117309\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mean Squared Error (MSE) on training data: 222.63500070528002\n",
      "Mean Squared Error (MSE) on training data: 220.38596313346343\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgbm = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "lgbm.fit(x_train, y_train)\n",
    "y_train_pred = lgbm.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = lgbm.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 222.23798952856544\n",
      "Mean Squared Error (MSE) on training data: 220.99855420137416\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_train_pred = xgb.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = xgb.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 224.15456874113096\n",
      "Mean Squared Error (MSE) on training data: 220.8654401992521\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "catboost = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, random_state=0, silent=True)\n",
    "catboost.fit(x_train, y_train)\n",
    "y_train_pred = catboost.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = catboost.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.1145516240328"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on training data: 37.18949009302405\n",
      "Mean Squared Error (MSE) on training data: 236.86375402852443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=300)\n",
    "rf.fit(x_train,y_train)\n",
    "y_train_pred = rf.predict(x_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse}\")\n",
    "y_val_pred = rf.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For iterations:5,depth:5,learning rate:0.01,\n",
      "                train accuracy:226.27356979987965 validation accuracy:221.15822256368483\n",
      "For iterations:5,depth:5,learning rate:0.1,\n",
      "                train accuracy:225.86728726405923 validation accuracy:221.0468542205591\n",
      "For iterations:5,depth:5,learning rate:0.5,\n",
      "                train accuracy:224.84914288929824 validation accuracy:221.28704377164667\n",
      "For iterations:5,depth:5,learning rate:1,\n",
      "                train accuracy:224.4846110554575 validation accuracy:221.79592411214685\n",
      "For iterations:5,depth:8,learning rate:0.01,\n",
      "                train accuracy:226.16977375733177 validation accuracy:221.14553332801313\n",
      "For iterations:5,depth:8,learning rate:0.1,\n",
      "                train accuracy:225.00320812132594 validation accuracy:220.84950308760125\n",
      "For iterations:5,depth:8,learning rate:0.5,\n",
      "                train accuracy:221.79997947389668 validation accuracy:220.9860566428631\n",
      "For iterations:5,depth:8,learning rate:1,\n",
      "                train accuracy:219.91320800801492 validation accuracy:223.71520617028028\n",
      "For iterations:5,depth:10,learning rate:0.01,\n",
      "                train accuracy:225.99702413265874 validation accuracy:221.10463459904076\n",
      "For iterations:5,depth:10,learning rate:0.1,\n",
      "                train accuracy:223.54650528354057 validation accuracy:220.70308385330907\n",
      "For iterations:5,depth:10,learning rate:0.5,\n",
      "                train accuracy:217.5702722046823 validation accuracy:221.99732924302808\n",
      "For iterations:5,depth:10,learning rate:1,\n",
      "                train accuracy:213.66166618276847 validation accuracy:227.1666104668554\n",
      "For iterations:5,depth:12,learning rate:0.01,\n",
      "                train accuracy:225.78393874486807 validation accuracy:221.13676024214962\n",
      "For iterations:5,depth:12,learning rate:0.1,\n",
      "                train accuracy:221.5493503637031 validation accuracy:220.9368736990708\n",
      "For iterations:5,depth:12,learning rate:0.5,\n",
      "                train accuracy:211.4845641614582 validation accuracy:223.3373120505659\n",
      "For iterations:5,depth:12,learning rate:1,\n",
      "                train accuracy:203.32873830812105 validation accuracy:233.6897869918625\n",
      "For iterations:5,depth:16,learning rate:0.01,\n",
      "                train accuracy:225.14015135361794 validation accuracy:221.08094238291466\n",
      "For iterations:5,depth:16,learning rate:0.1,\n",
      "                train accuracy:216.21824668839622 validation accuracy:220.8304078019855\n",
      "For iterations:5,depth:16,learning rate:0.5,\n",
      "                train accuracy:188.99017706738763 validation accuracy:228.1593204154929\n",
      "For iterations:5,depth:16,learning rate:1,\n",
      "                train accuracy:177.0327459953899 validation accuracy:242.74341403980267\n",
      "For iterations:25,depth:5,learning rate:0.01,\n",
      "                train accuracy:226.08616600197627 validation accuracy:221.06762321389186\n",
      "For iterations:25,depth:5,learning rate:0.1,\n",
      "                train accuracy:224.49292651613627 validation accuracy:220.75013093605253\n",
      "For iterations:25,depth:5,learning rate:0.5,\n",
      "                train accuracy:220.93008896805995 validation accuracy:221.50808831085476\n",
      "For iterations:25,depth:5,learning rate:1,\n",
      "                train accuracy:218.69291686037522 validation accuracy:224.742897130102\n",
      "For iterations:25,depth:8,learning rate:0.01,\n",
      "                train accuracy:225.5555669408512 validation accuracy:220.98951981059875\n",
      "For iterations:25,depth:8,learning rate:0.1,\n",
      "                train accuracy:221.15810544171796 validation accuracy:220.5375408673981\n",
      "For iterations:25,depth:8,learning rate:0.5,\n",
      "                train accuracy:210.45017517691335 validation accuracy:224.53871754428485\n",
      "For iterations:25,depth:8,learning rate:1,\n",
      "                train accuracy:203.45684428662446 validation accuracy:232.8786863168735\n",
      "For iterations:25,depth:10,learning rate:0.01,\n",
      "                train accuracy:224.83436633731804 validation accuracy:220.92326223085755\n",
      "For iterations:25,depth:10,learning rate:0.1,\n",
      "                train accuracy:216.97968063603494 validation accuracy:220.85132970884288\n",
      "For iterations:25,depth:10,learning rate:0.5,\n",
      "                train accuracy:197.9944765522435 validation accuracy:225.8624105095472\n",
      "For iterations:25,depth:10,learning rate:1,\n",
      "                train accuracy:185.75070311675506 validation accuracy:241.64892695709676\n",
      "For iterations:25,depth:12,learning rate:0.01,\n",
      "                train accuracy:223.57758580624036 validation accuracy:220.89997174775118\n",
      "For iterations:25,depth:12,learning rate:0.1,\n",
      "                train accuracy:209.77504564992907 validation accuracy:221.51202126437667\n",
      "For iterations:25,depth:12,learning rate:0.5,\n",
      "                train accuracy:183.13063424331023 validation accuracy:231.09926107888384\n",
      "For iterations:25,depth:12,learning rate:1,\n",
      "                train accuracy:160.13210621713742 validation accuracy:254.25282711121758\n",
      "For iterations:25,depth:16,learning rate:0.01,\n",
      "                train accuracy:220.6072655926394 validation accuracy:220.9541518597154\n",
      "For iterations:25,depth:16,learning rate:0.1,\n",
      "                train accuracy:191.96221045972604 validation accuracy:223.32216608112032\n",
      "For iterations:25,depth:16,learning rate:0.5,\n",
      "                train accuracy:143.22306000661837 validation accuracy:239.12017234316474\n",
      "For iterations:25,depth:16,learning rate:1,\n",
      "                train accuracy:102.19771652435305 validation accuracy:276.64711067800636\n",
      "For iterations:50,depth:5,learning rate:0.01,\n",
      "                train accuracy:225.85816317261086 validation accuracy:220.98413978583122\n",
      "For iterations:50,depth:5,learning rate:0.1,\n",
      "                train accuracy:223.35785160173901 validation accuracy:220.72166131184665\n",
      "For iterations:50,depth:5,learning rate:0.5,\n",
      "                train accuracy:216.52807749590292 validation accuracy:223.09083777267742\n",
      "For iterations:50,depth:5,learning rate:1,\n",
      "                train accuracy:213.32557003170297 validation accuracy:226.82761182267902\n",
      "For iterations:50,depth:8,learning rate:0.01,\n",
      "                train accuracy:224.9173972585938 validation accuracy:220.86002398834427\n",
      "For iterations:50,depth:8,learning rate:0.1,\n",
      "                train accuracy:217.49603557897493 validation accuracy:220.5581121595511\n",
      "For iterations:50,depth:8,learning rate:0.5,\n",
      "                train accuracy:199.82153353609368 validation accuracy:227.0471862718844\n",
      "For iterations:50,depth:8,learning rate:1,\n",
      "                train accuracy:188.9953367329276 validation accuracy:242.49622455674006\n",
      "For iterations:50,depth:10,learning rate:0.01,\n",
      "                train accuracy:223.52663252387978 validation accuracy:220.7430896775456\n",
      "For iterations:50,depth:10,learning rate:0.1,\n",
      "                train accuracy:210.1203641730377 validation accuracy:221.30723978111664\n",
      "For iterations:50,depth:10,learning rate:0.5,\n",
      "                train accuracy:179.30108200104917 validation accuracy:230.4289053735759\n",
      "For iterations:50,depth:10,learning rate:1,\n",
      "                train accuracy:163.36362364828608 validation accuracy:254.29064229295182\n",
      "For iterations:50,depth:12,learning rate:0.01,\n",
      "                train accuracy:221.24491212170577 validation accuracy:220.7188463494584\n",
      "For iterations:50,depth:12,learning rate:0.1,\n",
      "                train accuracy:199.50535594574131 validation accuracy:222.99257373221724\n",
      "For iterations:50,depth:12,learning rate:0.5,\n",
      "                train accuracy:156.4182568669433 validation accuracy:238.29714609883754\n",
      "For iterations:50,depth:12,learning rate:1,\n",
      "                train accuracy:127.77578969437315 validation accuracy:269.6336183297372\n",
      "For iterations:50,depth:16,learning rate:0.01,\n",
      "                train accuracy:215.83250480065843 validation accuracy:220.83765796322965\n",
      "For iterations:50,depth:16,learning rate:0.1,\n",
      "                train accuracy:172.6498099293479 validation accuracy:227.1226322533013\n",
      "For iterations:50,depth:16,learning rate:0.5,\n",
      "                train accuracy:104.53787154788678 validation accuracy:250.34653228700284\n",
      "For iterations:50,depth:16,learning rate:1,\n",
      "                train accuracy:67.57980988100414 validation accuracy:294.01499329398865\n",
      "For iterations:75,depth:5,learning rate:0.01,\n",
      "                train accuracy:225.65921378826013 validation accuracy:220.92701381900747\n",
      "For iterations:75,depth:5,learning rate:0.1,\n",
      "                train accuracy:222.35428288496234 validation accuracy:220.7028102464879\n",
      "For iterations:75,depth:5,learning rate:0.5,\n",
      "                train accuracy:213.38464440010824 validation accuracy:224.21607252854795\n",
      "For iterations:75,depth:5,learning rate:1,\n",
      "                train accuracy:208.66258031243834 validation accuracy:229.9539591290411\n",
      "For iterations:75,depth:8,learning rate:0.01,\n",
      "                train accuracy:224.30918797960098 validation accuracy:220.7552658749747\n",
      "For iterations:75,depth:8,learning rate:0.1,\n",
      "                train accuracy:214.50552301296003 validation accuracy:220.8367467668409\n",
      "For iterations:75,depth:8,learning rate:0.5,\n",
      "                train accuracy:192.32774888862374 validation accuracy:228.5083315728724\n",
      "For iterations:75,depth:8,learning rate:1,\n",
      "                train accuracy:176.9809404138225 validation accuracy:249.20889838676624\n",
      "For iterations:75,depth:10,learning rate:0.01,\n",
      "                train accuracy:222.33594203022272 validation accuracy:220.5898429540034\n",
      "For iterations:75,depth:10,learning rate:0.1,\n",
      "                train accuracy:205.8737517649726 validation accuracy:222.09642692360828\n",
      "For iterations:75,depth:10,learning rate:0.5,\n",
      "                train accuracy:168.48682144644576 validation accuracy:233.85808807638531\n",
      "For iterations:75,depth:10,learning rate:1,\n",
      "                train accuracy:146.17254249274214 validation accuracy:264.44338285383805\n",
      "For iterations:75,depth:12,learning rate:0.01,\n",
      "                train accuracy:219.49164690456678 validation accuracy:220.6112156180169\n",
      "For iterations:75,depth:12,learning rate:0.1,\n",
      "                train accuracy:191.47057295932427 validation accuracy:224.12266692753997\n",
      "For iterations:75,depth:12,learning rate:0.5,\n",
      "                train accuracy:137.29802200860306 validation accuracy:244.27575713043944\n",
      "For iterations:75,depth:12,learning rate:1,\n",
      "                train accuracy:108.41415928671496 validation accuracy:278.3125517179636\n",
      "For iterations:75,depth:16,learning rate:0.01,\n",
      "                train accuracy:211.52112395041374 validation accuracy:220.95334415517965\n",
      "For iterations:75,depth:16,learning rate:0.1,\n",
      "                train accuracy:157.97024176318592 validation accuracy:230.26387974838664\n",
      "For iterations:75,depth:16,learning rate:0.5,\n",
      "                train accuracy:80.11557196778541 validation accuracy:259.4024702185918\n",
      "For iterations:75,depth:16,learning rate:1,\n",
      "                train accuracy:50.26144289260074 validation accuracy:305.0734867036636\n",
      "For iterations:100,depth:5,learning rate:0.01,\n",
      "                train accuracy:225.468671216681 validation accuracy:220.85951830655176\n",
      "For iterations:100,depth:5,learning rate:0.1,\n",
      "                train accuracy:221.4790239749303 validation accuracy:220.77809544976841\n",
      "For iterations:100,depth:5,learning rate:0.5,\n",
      "                train accuracy:210.2788699071315 validation accuracy:224.84947252495232\n",
      "For iterations:100,depth:5,learning rate:1,\n",
      "                train accuracy:204.68375688666472 validation accuracy:232.59353983165704\n",
      "For iterations:100,depth:8,learning rate:0.01,\n",
      "                train accuracy:223.74686462233842 validation accuracy:220.68787953689375\n",
      "For iterations:100,depth:8,learning rate:0.1,\n",
      "                train accuracy:212.15206462728364 validation accuracy:220.9841308626611\n",
      "For iterations:100,depth:8,learning rate:0.5,\n",
      "                train accuracy:184.99490421929005 validation accuracy:230.7185782367434\n",
      "For iterations:100,depth:8,learning rate:1,\n",
      "                train accuracy:167.00084199079552 validation accuracy:254.9268099387164\n",
      "For iterations:100,depth:10,learning rate:0.01,\n",
      "                train accuracy:221.36514218523564 validation accuracy:220.49280524651965\n",
      "For iterations:100,depth:10,learning rate:0.1,\n",
      "                train accuracy:201.06494627242716 validation accuracy:222.28910190384718\n",
      "For iterations:100,depth:10,learning rate:0.5,\n",
      "                train accuracy:157.44140029499295 validation accuracy:237.66592040514456\n",
      "For iterations:100,depth:10,learning rate:1,\n",
      "                train accuracy:133.78293927882956 validation accuracy:273.6985350652583\n",
      "For iterations:100,depth:12,learning rate:0.01,\n",
      "                train accuracy:217.86344144549253 validation accuracy:220.58496024598816\n",
      "For iterations:100,depth:12,learning rate:0.1,\n",
      "                train accuracy:185.0811103571206 validation accuracy:225.69095129521273\n",
      "For iterations:100,depth:12,learning rate:0.5,\n",
      "                train accuracy:123.52611804780366 validation accuracy:248.91326193410984\n",
      "For iterations:100,depth:12,learning rate:1,\n",
      "                train accuracy:93.13283094947032 validation accuracy:286.30597602007293\n",
      "For iterations:100,depth:16,learning rate:0.01,\n",
      "                train accuracy:207.45446173884503 validation accuracy:221.12995680496658\n",
      "For iterations:100,depth:16,learning rate:0.1,\n",
      "                train accuracy:146.72606330406373 validation accuracy:232.70473416595777\n",
      "For iterations:100,depth:16,learning rate:0.5,\n",
      "                train accuracy:67.0730261067735 validation accuracy:265.81207346357604\n",
      "For iterations:100,depth:16,learning rate:1,\n",
      "                train accuracy:37.40579589103559 validation accuracy:314.5183499185214\n",
      "For iterations:150,depth:5,learning rate:0.01,\n",
      "                train accuracy:225.12062614300652 validation accuracy:220.79847771195307\n",
      "For iterations:150,depth:5,learning rate:0.1,\n",
      "                train accuracy:219.2667692394079 validation accuracy:220.77770374515495\n",
      "For iterations:150,depth:5,learning rate:0.5,\n",
      "                train accuracy:205.4699686572394 validation accuracy:225.68579098531865\n",
      "For iterations:150,depth:5,learning rate:1,\n",
      "                train accuracy:198.13774416162752 validation accuracy:236.72349603064612\n",
      "For iterations:150,depth:8,learning rate:0.01,\n",
      "                train accuracy:222.75859858048602 validation accuracy:220.5709005883729\n",
      "For iterations:150,depth:8,learning rate:0.1,\n",
      "                train accuracy:206.79527654163076 validation accuracy:221.16204766453524\n",
      "For iterations:150,depth:8,learning rate:0.5,\n",
      "                train accuracy:173.11215530921058 validation accuracy:235.04491477892182\n",
      "For iterations:150,depth:8,learning rate:1,\n",
      "                train accuracy:153.07217883881015 validation accuracy:264.1396724541227\n",
      "For iterations:150,depth:10,learning rate:0.01,\n",
      "                train accuracy:219.58957829358658 validation accuracy:220.41036154866916\n",
      "For iterations:150,depth:10,learning rate:0.1,\n",
      "                train accuracy:192.60438189065977 validation accuracy:223.61433391930896\n",
      "For iterations:150,depth:10,learning rate:0.5,\n",
      "                train accuracy:140.13253071465667 validation accuracy:244.27568435795757\n",
      "For iterations:150,depth:10,learning rate:1,\n",
      "                train accuracy:111.55722485564193 validation accuracy:287.6625190759895\n",
      "For iterations:150,depth:12,learning rate:0.01,\n",
      "                train accuracy:214.7683265575767 validation accuracy:220.5642764526497\n",
      "For iterations:150,depth:12,learning rate:0.1,\n",
      "                train accuracy:172.45307968614804 validation accuracy:227.6362067710048\n",
      "For iterations:150,depth:12,learning rate:0.5,\n",
      "                train accuracy:103.9344082983271 validation accuracy:257.5099842395035\n",
      "For iterations:150,depth:12,learning rate:1,\n",
      "                train accuracy:73.07623070397001 validation accuracy:299.99191302686506\n",
      "For iterations:150,depth:16,learning rate:0.01,\n",
      "                train accuracy:200.6388582969458 validation accuracy:221.57478328791075\n",
      "For iterations:150,depth:16,learning rate:0.1,\n",
      "                train accuracy:126.9507481086538 validation accuracy:237.3592563225918\n",
      "For iterations:150,depth:16,learning rate:0.5,\n",
      "                train accuracy:48.57232850887349 validation accuracy:274.6360555085345\n",
      "For iterations:150,depth:16,learning rate:1,\n",
      "                train accuracy:24.00290758042633 validation accuracy:324.65801069875334\n",
      "For iterations:200,depth:5,learning rate:0.01,\n",
      "                train accuracy:224.80668967230423 validation accuracy:220.7254547362458\n",
      "For iterations:200,depth:5,learning rate:0.1,\n",
      "                train accuracy:217.4337064100896 validation accuracy:220.80562460074114\n",
      "For iterations:200,depth:5,learning rate:0.5,\n",
      "                train accuracy:201.14461912509466 validation accuracy:227.3806627526674\n",
      "For iterations:200,depth:5,learning rate:1,\n",
      "                train accuracy:193.22873869965474 validation accuracy:239.46120627630262\n",
      "For iterations:200,depth:8,learning rate:0.01,\n",
      "                train accuracy:221.81981013632475 validation accuracy:220.49015090572618\n",
      "For iterations:200,depth:8,learning rate:0.1,\n",
      "                train accuracy:202.2020612561283 validation accuracy:221.82664350452848\n",
      "For iterations:200,depth:8,learning rate:0.5,\n",
      "                train accuracy:164.25198570180666 validation accuracy:238.19034461436604\n",
      "For iterations:200,depth:8,learning rate:1,\n",
      "                train accuracy:142.50452875074785 validation accuracy:270.35200154932534\n",
      "For iterations:200,depth:10,learning rate:0.01,\n",
      "                train accuracy:217.9628462837106 validation accuracy:220.38100427798517\n",
      "For iterations:200,depth:10,learning rate:0.1,\n",
      "                train accuracy:185.78694586074442 validation accuracy:224.4689384689475\n",
      "For iterations:200,depth:10,learning rate:0.5,\n",
      "                train accuracy:126.79600699071754 validation accuracy:248.33949767836762\n",
      "For iterations:200,depth:10,learning rate:1,\n",
      "                train accuracy:98.05990599793247 validation accuracy:298.9109528725693\n",
      "For iterations:200,depth:12,learning rate:0.01,\n",
      "                train accuracy:212.15688454516152 validation accuracy:220.63477776728973\n",
      "For iterations:200,depth:12,learning rate:0.1,\n",
      "                train accuracy:162.678568888319 validation accuracy:229.9936475032444\n",
      "For iterations:200,depth:12,learning rate:0.5,\n",
      "                train accuracy:89.7877038231399 validation accuracy:264.2519817968077\n",
      "For iterations:200,depth:12,learning rate:1,\n",
      "                train accuracy:58.66553433476254 validation accuracy:311.55224200188576\n",
      "For iterations:200,depth:16,learning rate:0.01,\n",
      "                train accuracy:195.11219521411311 validation accuracy:222.12506557502041\n",
      "For iterations:200,depth:16,learning rate:0.1,\n",
      "                train accuracy:112.96321342759923 validation accuracy:241.03486620502088\n",
      "For iterations:200,depth:16,learning rate:0.5,\n",
      "                train accuracy:36.78512847048189 validation accuracy:281.690682719243\n",
      "For iterations:200,depth:16,learning rate:1,\n",
      "                train accuracy:17.377993458688298 validation accuracy:331.2493009515484\n",
      "For iterations:250,depth:5,learning rate:0.01,\n",
      "                train accuracy:224.5088550860654 validation accuracy:220.7000148180611\n",
      "For iterations:250,depth:5,learning rate:0.1,\n",
      "                train accuracy:215.75359687300102 validation accuracy:221.00279445749277\n",
      "For iterations:250,depth:5,learning rate:0.5,\n",
      "                train accuracy:197.25147681682876 validation accuracy:228.05645431473852\n",
      "For iterations:250,depth:5,learning rate:1,\n",
      "                train accuracy:188.82784121225703 validation accuracy:241.50807627146932\n",
      "For iterations:250,depth:8,learning rate:0.01,\n",
      "                train accuracy:220.98261697492052 validation accuracy:220.4480254972506\n",
      "For iterations:250,depth:8,learning rate:0.1,\n",
      "                train accuracy:198.37521772140684 validation accuracy:222.343691899252\n",
      "For iterations:250,depth:8,learning rate:0.5,\n",
      "                train accuracy:155.81983893123845 validation accuracy:241.2214350778066\n",
      "For iterations:250,depth:8,learning rate:1,\n",
      "                train accuracy:132.16491991501184 validation accuracy:281.4560794943107\n",
      "For iterations:250,depth:10,learning rate:0.01,\n",
      "                train accuracy:216.36524310836765 validation accuracy:220.38219076005046\n",
      "For iterations:250,depth:10,learning rate:0.1,\n",
      "                train accuracy:179.6439262917282 validation accuracy:225.64076781613832\n",
      "For iterations:250,depth:10,learning rate:0.5,\n",
      "                train accuracy:117.3040722160151 validation accuracy:252.2831338695526\n",
      "For iterations:250,depth:10,learning rate:1,\n",
      "                train accuracy:86.12694316425176 validation accuracy:306.92092555855425\n",
      "For iterations:250,depth:12,learning rate:0.01,\n",
      "                train accuracy:209.90510472779923 validation accuracy:220.71469703462128\n",
      "For iterations:250,depth:12,learning rate:0.1,\n",
      "                train accuracy:154.19269277264894 validation accuracy:231.48782521142678\n",
      "For iterations:250,depth:12,learning rate:0.5,\n",
      "                train accuracy:78.48801363112858 validation accuracy:269.8709451445851\n",
      "For iterations:250,depth:12,learning rate:1,\n",
      "                train accuracy:48.38205283791094 validation accuracy:319.69565406137474\n",
      "For iterations:250,depth:16,learning rate:0.01,\n",
      "                train accuracy:190.50393539549634 validation accuracy:222.65053416977543\n",
      "For iterations:250,depth:16,learning rate:0.1,\n",
      "                train accuracy:102.16195343992082 validation accuracy:244.22784252602062\n",
      "For iterations:250,depth:16,learning rate:0.5,\n",
      "                train accuracy:29.465580468901305 validation accuracy:286.7447468428724\n",
      "For iterations:250,depth:16,learning rate:1,\n",
      "                train accuracy:13.574695976001845 validation accuracy:335.71482206678274\n",
      "For iterations:300,depth:5,learning rate:0.01,\n",
      "                train accuracy:224.24724701765544 validation accuracy:220.66248156914702\n",
      "For iterations:300,depth:5,learning rate:0.1,\n",
      "                train accuracy:214.3516330669527 validation accuracy:221.03513872807534\n",
      "For iterations:300,depth:5,learning rate:0.5,\n",
      "                train accuracy:193.56635857899118 validation accuracy:229.59082390768666\n",
      "For iterations:300,depth:5,learning rate:1,\n",
      "                train accuracy:185.25954396950803 validation accuracy:242.92579365053783\n",
      "For iterations:300,depth:8,learning rate:0.01,\n",
      "                train accuracy:220.1907676092373 validation accuracy:220.43823293908915\n",
      "For iterations:300,depth:8,learning rate:0.1,\n",
      "                train accuracy:194.58467355501804 validation accuracy:222.87986103848286\n",
      "For iterations:300,depth:8,learning rate:0.5,\n",
      "                train accuracy:148.96848084832564 validation accuracy:243.98999893569962\n",
      "For iterations:300,depth:8,learning rate:1,\n",
      "                train accuracy:124.93285529593281 validation accuracy:284.3400187820056\n",
      "For iterations:300,depth:10,learning rate:0.01,\n",
      "                train accuracy:215.00811711040436 validation accuracy:220.42935211237912\n",
      "For iterations:300,depth:10,learning rate:0.1,\n",
      "                train accuracy:173.6478849119547 validation accuracy:226.80684535325364\n",
      "For iterations:300,depth:10,learning rate:0.5,\n",
      "                train accuracy:108.26837262582829 validation accuracy:256.3942606729034\n",
      "For iterations:300,depth:10,learning rate:1,\n",
      "                train accuracy:77.08335646285653 validation accuracy:312.2298017197543\n",
      "For iterations:300,depth:12,learning rate:0.01,\n",
      "                train accuracy:207.696923337083 validation accuracy:220.87944413046353\n",
      "For iterations:300,depth:12,learning rate:0.1,\n",
      "                train accuracy:146.56968525060742 validation accuracy:233.25369374047668\n",
      "For iterations:300,depth:12,learning rate:0.5,\n",
      "                train accuracy:69.57453644617821 validation accuracy:273.5042536231217\n",
      "For iterations:300,depth:12,learning rate:1,\n",
      "                train accuracy:40.658203929036986 validation accuracy:325.0477709669128\n",
      "For iterations:300,depth:16,learning rate:0.01,\n",
      "                train accuracy:186.09029749424346 validation accuracy:223.23047122378983\n",
      "For iterations:300,depth:16,learning rate:0.1,\n",
      "                train accuracy:93.20102748544254 validation accuracy:247.0601876328233\n",
      "For iterations:300,depth:16,learning rate:0.5,\n",
      "                train accuracy:24.166647634981057 validation accuracy:291.90120363654796\n",
      "For iterations:300,depth:16,learning rate:1,\n",
      "                train accuracy:11.50812008503348 validation accuracy:338.61634027643845\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "depth1 = [5,8,10,12,16]\n",
    "features= [0.01,0.1,0.5,1]\n",
    "estimators = [5,25,50,75,100,150,200,250,300]\n",
    "for i in estimators:\n",
    "    for j in depth1:\n",
    "        for k in features:\n",
    "            # for l in min_samples_s:\n",
    "                tree_= CatBoostRegressor(iterations=i, learning_rate=k, depth=j, random_state=0, silent=True)\n",
    "                tree_.fit(x_train,y_train)\n",
    "                y_train_pred = tree_.predict(x_train)\n",
    "                train_accuracy = mean_squared_error(y_train, y_train_pred)\n",
    "                y_val_pred = tree_.predict(x_val)\n",
    "                val_accuracy = mean_squared_error(y_val, y_val_pred)\n",
    "                list1.append((i,j,k,train_accuracy,val_accuracy))\n",
    "                print(f'''For iterations:{i},depth:{j},learning rate:{k},\n",
    "                train accuracy:{train_accuracy} validation accuracy:{val_accuracy}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226.27356979987965, 225.86728726405923, 224.84914288929824, 224.4846110554575, 226.16977375733177, 225.00320812132594, 221.79997947389668, 219.91320800801492, 225.99702413265874, 223.54650528354057, 217.5702722046823, 213.66166618276847, 225.78393874486807, 221.5493503637031, 211.4845641614582, 203.32873830812105, 225.14015135361794, 216.21824668839622, 188.99017706738763, 177.0327459953899, 226.08616600197627, 224.49292651613627, 220.93008896805995, 218.69291686037522, 225.5555669408512, 221.15810544171796, 210.45017517691335, 203.45684428662446, 224.83436633731804, 216.97968063603494, 197.9944765522435, 185.75070311675506, 223.57758580624036, 209.77504564992907, 183.13063424331023, 160.13210621713742, 220.6072655926394, 191.96221045972604, 143.22306000661837, 102.19771652435305, 225.85816317261086, 223.35785160173901, 216.52807749590292, 213.32557003170297, 224.9173972585938, 217.49603557897493, 199.82153353609368, 188.9953367329276, 223.52663252387978, 210.1203641730377, 179.30108200104917, 163.36362364828608, 221.24491212170577, 199.50535594574131, 156.4182568669433, 127.77578969437315, 215.83250480065843, 172.6498099293479, 104.53787154788678, 67.57980988100414, 225.65921378826013, 222.35428288496234, 213.38464440010824, 208.66258031243834, 224.30918797960098, 214.50552301296003, 192.32774888862374, 176.9809404138225, 222.33594203022272, 205.8737517649726, 168.48682144644576, 146.17254249274214, 219.49164690456678, 191.47057295932427, 137.29802200860306, 108.41415928671496, 211.52112395041374, 157.97024176318592, 80.11557196778541, 50.26144289260074, 225.468671216681, 221.4790239749303, 210.2788699071315, 204.68375688666472, 223.74686462233842, 212.15206462728364, 184.99490421929005, 167.00084199079552, 221.36514218523564, 201.06494627242716, 157.44140029499295, 133.78293927882956, 217.86344144549253, 185.0811103571206, 123.52611804780366, 93.13283094947032, 207.45446173884503, 146.72606330406373, 67.0730261067735, 37.40579589103559, 225.12062614300652, 219.2667692394079, 205.4699686572394, 198.13774416162752, 222.75859858048602, 206.79527654163076, 173.11215530921058, 153.07217883881015, 219.58957829358658, 192.60438189065977, 140.13253071465667, 111.55722485564193, 214.7683265575767, 172.45307968614804, 103.9344082983271, 73.07623070397001, 200.6388582969458, 126.9507481086538, 48.57232850887349, 24.00290758042633, 224.80668967230423, 217.4337064100896, 201.14461912509466, 193.22873869965474, 221.81981013632475, 202.2020612561283, 164.25198570180666, 142.50452875074785, 217.9628462837106, 185.78694586074442, 126.79600699071754, 98.05990599793247, 212.15688454516152, 162.678568888319, 89.7877038231399, 58.66553433476254, 195.11219521411311, 112.96321342759923, 36.78512847048189, 17.377993458688298, 224.5088550860654, 215.75359687300102, 197.25147681682876, 188.82784121225703, 220.98261697492052, 198.37521772140684, 155.81983893123845, 132.16491991501184, 216.36524310836765, 179.6439262917282, 117.3040722160151, 86.12694316425176, 209.90510472779923, 154.19269277264894, 78.48801363112858, 48.38205283791094, 190.50393539549634, 102.16195343992082, 29.465580468901305, 13.574695976001845, 224.24724701765544, 214.3516330669527, 193.56635857899118, 185.25954396950803, 220.1907676092373, 194.58467355501804, 148.96848084832564, 124.93285529593281, 215.00811711040436, 173.6478849119547, 108.26837262582829, 77.08335646285653, 207.696923337083, 146.56968525060742, 69.57453644617821, 40.658203929036986, 186.09029749424346, 93.20102748544254, 24.166647634981057, 11.50812008503348]\n",
      "[221.15822256368483, 221.0468542205591, 221.28704377164667, 221.79592411214685, 221.14553332801313, 220.84950308760125, 220.9860566428631, 223.71520617028028, 221.10463459904076, 220.70308385330907, 221.99732924302808, 227.1666104668554, 221.13676024214962, 220.9368736990708, 223.3373120505659, 233.6897869918625, 221.08094238291466, 220.8304078019855, 228.1593204154929, 242.74341403980267, 221.06762321389186, 220.75013093605253, 221.50808831085476, 224.742897130102, 220.98951981059875, 220.5375408673981, 224.53871754428485, 232.8786863168735, 220.92326223085755, 220.85132970884288, 225.8624105095472, 241.64892695709676, 220.89997174775118, 221.51202126437667, 231.09926107888384, 254.25282711121758, 220.9541518597154, 223.32216608112032, 239.12017234316474, 276.64711067800636, 220.98413978583122, 220.72166131184665, 223.09083777267742, 226.82761182267902, 220.86002398834427, 220.5581121595511, 227.0471862718844, 242.49622455674006, 220.7430896775456, 221.30723978111664, 230.4289053735759, 254.29064229295182, 220.7188463494584, 222.99257373221724, 238.29714609883754, 269.6336183297372, 220.83765796322965, 227.1226322533013, 250.34653228700284, 294.01499329398865, 220.92701381900747, 220.7028102464879, 224.21607252854795, 229.9539591290411, 220.7552658749747, 220.8367467668409, 228.5083315728724, 249.20889838676624, 220.5898429540034, 222.09642692360828, 233.85808807638531, 264.44338285383805, 220.6112156180169, 224.12266692753997, 244.27575713043944, 278.3125517179636, 220.95334415517965, 230.26387974838664, 259.4024702185918, 305.0734867036636, 220.85951830655176, 220.77809544976841, 224.84947252495232, 232.59353983165704, 220.68787953689375, 220.9841308626611, 230.7185782367434, 254.9268099387164, 220.49280524651965, 222.28910190384718, 237.66592040514456, 273.6985350652583, 220.58496024598816, 225.69095129521273, 248.91326193410984, 286.30597602007293, 221.12995680496658, 232.70473416595777, 265.81207346357604, 314.5183499185214, 220.79847771195307, 220.77770374515495, 225.68579098531865, 236.72349603064612, 220.5709005883729, 221.16204766453524, 235.04491477892182, 264.1396724541227, 220.41036154866916, 223.61433391930896, 244.27568435795757, 287.6625190759895, 220.5642764526497, 227.6362067710048, 257.5099842395035, 299.99191302686506, 221.57478328791075, 237.3592563225918, 274.6360555085345, 324.65801069875334, 220.7254547362458, 220.80562460074114, 227.3806627526674, 239.46120627630262, 220.49015090572618, 221.82664350452848, 238.19034461436604, 270.35200154932534, 220.38100427798517, 224.4689384689475, 248.33949767836762, 298.9109528725693, 220.63477776728973, 229.9936475032444, 264.2519817968077, 311.55224200188576, 222.12506557502041, 241.03486620502088, 281.690682719243, 331.2493009515484, 220.7000148180611, 221.00279445749277, 228.05645431473852, 241.50807627146932, 220.4480254972506, 222.343691899252, 241.2214350778066, 281.4560794943107, 220.38219076005046, 225.64076781613832, 252.2831338695526, 306.92092555855425, 220.71469703462128, 231.48782521142678, 269.8709451445851, 319.69565406137474, 222.65053416977543, 244.22784252602062, 286.7447468428724, 335.71482206678274, 220.66248156914702, 221.03513872807534, 229.59082390768666, 242.92579365053783, 220.43823293908915, 222.87986103848286, 243.98999893569962, 284.3400187820056, 220.42935211237912, 226.80684535325364, 256.3942606729034, 312.2298017197543, 220.87944413046353, 233.25369374047668, 273.5042536231217, 325.0477709669128, 223.23047122378983, 247.0601876328233, 291.90120363654796, 338.61634027643845]\n"
     ]
    }
   ],
   "source": [
    "all_train_acc=[list1[i][3] for i in range(len(list1))]\n",
    "all_val_acc=[list1[i][4] for i in range(len(list1))]\n",
    "print(all_train_acc)\n",
    "print(all_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220.38100427798517,\n",
       " 220.38219076005046,\n",
       " 220.41036154866916,\n",
       " 220.42935211237912,\n",
       " 220.43823293908915,\n",
       " 220.4480254972506,\n",
       " 220.49015090572618,\n",
       " 220.49280524651965,\n",
       " 220.5375408673981,\n",
       " 220.5581121595511]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "max_5_val_acc = heapq.nsmallest(10, all_val_acc)\n",
    "max_5_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10, 0.01, 217.9628462837106, 220.38100427798517)\n",
      "(250, 10, 0.01, 216.36524310836765, 220.38219076005046)\n",
      "(150, 10, 0.01, 219.58957829358658, 220.41036154866916)\n",
      "(300, 10, 0.01, 215.00811711040436, 220.42935211237912)\n",
      "(300, 8, 0.01, 220.1907676092373, 220.43823293908915)\n",
      "(250, 8, 0.01, 220.98261697492052, 220.4480254972506)\n",
      "(200, 8, 0.01, 221.81981013632475, 220.49015090572618)\n",
      "(100, 10, 0.01, 221.36514218523564, 220.49280524651965)\n",
      "(25, 8, 0.1, 221.15810544171796, 220.5375408673981)\n",
      "(50, 8, 0.1, 217.49603557897493, 220.5581121595511)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(max_5_val_acc)):\n",
    "    print(list1[all_val_acc.index(max_5_val_acc[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
